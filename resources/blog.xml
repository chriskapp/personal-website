<?xml version="1.0"?>
<feed>
    <entry>
        <title>Lessons learned from building a Docker-based server panel</title>
        <updated>2025-06-28T17:03:00Z</updated>
        <summary>
            This post talks about the lessons learned from building a Docker-based server panel to self-host apps.
        </summary>
        <category term="docker" />
        <category term="self-host" />
        <category term="server" />
        <category term="panel" />
        <content type="html"><![CDATA[

<p>Today I have released a first version of <a href="https://github.com/apioo/fusio-plant">Fusio Plant</a> which is an open source
server management tool to easily self-host apps on your server, in this post I like to share some experiences of this process.</p>

<p>While building Plant, we had the goal to keep the host as small as possible, we basically only wanted to install Nginx and Docker
and start all projects through a simple <code>docker-compose.yml</code> file. We also wanted to run the Plant app itself as docker container
so that it is easy to update the server panel itself. Moving the Plant app into a docker container means also that we can no
longer directly execute commands on the host. In general, this is a good thing, but for a server panel we need the option to change
i.e. the Nginx configuration or run Docker commands on the host.</p>

<h2>Host Docker communication</h2>

<p>In the development process, we had developed three versions to enable this Docker to host communication. These ideas are maybe
also useful for other scenarios, so I will walk you through each version.</p>

<p><b>Cron</b></p>

<p>The first implementation used a simple cronjob which executed a bash script. The bash script walked through each file in an
<code>input/</code> folder, executed each file and wrote the output to an <code>output/</code> folder. Those <code>input/</code>
and <code>output/</code> folders are also mounted into the docker container and inside the container we wrote a command into the
<code>input/</code> folder and waited until the result was available at the <code>output/</code> folder.</p>

<p>The biggest limitation of this solution was speed since cron can execute a script only once every minute. This means in the worst
case, a user needs to wait almost a minute for the command to be executed.</p>

<p><b>inotifywait</b></p>

<p>To improve the performance we tried to use <code>inotifywait</code> which is basically a tool which you can use to listen for
file changes inside a folder. The setup is basically identical to the cron version but instead of cron we use <code>inotifywait</code>
to listen for file changes inside the <code>input/</code> folder and then write the result to the <code>output/</code> folder.
To run this script we have also used <a href="https://supervisord.org/">supervisord</a> to keep the bash script alive in case of errors.</p>

<p>Initially this has worked and improved the performance greatly, but unfortunately there are some scenarios where <code>inotifywait</code>
could not detect file changes in case the Docker app placed multiple files into the <code>input/</code> folder.</p>

<p><b>Named pipe</b></p>

<p>As the last and final solution, we have changed the input folder to a <a href="https://en.wikipedia.org/wiki/Named_pipe">named pipe</a>.
We can then mount this pipe into our Docker container and write events directly into this pipe. On the host we can then listen to this
pipe and execute events directly on occurrence.</p>

<p>The <a href="https://github.com/apioo/fusio-plant/blob/main/bash/executor.sh#L157">bash script</a> on the host can now
easily listen for changes on the pipe s.</p>

<pre>
input=/opt/plant/input

while true
do
  while read -r line; do execute_command "$line"; done < $input
  sleep 1
done
</pre>

<p>To write events to the pipe, we can use basic file functions s.</p>

<pre>
$input = fopen('/tmp/input', 'w');
fwrite($input, '{"type": "my_command"}');
fclose($input);
</pre>

<p>After writing the command to the pipe we can directly check the <code>/output</code> file and wait for
a response. To veriy that the script was fully executed we check for a specific <code>--EOF-MARKER--</code>
marker at the end of the file and if its available we stop reading the file.</p>

<pre>
$response = '';
$outputFile = '/tmp/output';
$output = fopen($outputFile, 'r');
$count = 0;
while ($count < 32) {
    $size = filesize($outputFile);
    if ($size > 0) {
        $response.= fread($output, $size);
    }

    if (str_contains($response, '--EOF-MARKER--')) {
        break;
    }

    usleep(100_000);
    clearstatcache();

    $count++;
}

fclose($output);
</pre>

<p>The <code>clearstatcache</code> call in the snippet above is crucial since PHP automatically caches the responses
of the <code>filesize</code> function, so we need to clear the cache on every iteration to get the live file size which
often changes on command execution.</p>

<h2>Conclusion</h2>

<p>As a conclusion, we have looked into three solutions to enable Docker host communication. In our case, the named pipe
solution works perfectly since it is fast and lightweight, and we can now easily execute commands on the host system.
In case you are interested in a new Docker-based server management tool, check out the <a href="https://github.com/apioo/fusio-plant">Plant GitHub repository</a>.</p>

]]></content>
    </entry>
    <entry>
        <title>TypeSchema a JSON specification to describe data models</title>
        <updated>2025-01-02T23:03:00Z</updated>
        <summary>
            This post talks about the latest TypeSchema version and how it can be used to generate models in different environments.
        </summary>
        <category term="type-schema" />
        <category term="json-schema" />
        <category term="data" />
        <category term="model" />
        <category term="specification" />
        <content type="html"><![CDATA[

<p>In this post I like to talk about the <a href="https://typeschema.org/">TypeSchema</a> specification and the changes of the latest version.</p>

<p>To start, <a href="https://typeschema.org/">TypeSchema</a> is a JSON specification to describe data models in a language neutral format.
Basically it can be seen as an alternative to JSON schema with a focus on code generation (and not validation).
It helps you to build type-safe applications by sharing core data models in different environments.</p>

<p>The TypeSchema specification is reversible, this means you can transform a TypeSchema specification into actual code and then use
a reflection library to turn this code back into a TypeSchema specification without any data loss s.</p>

<hr>

<figure>
<pre style="text-align:center">
Generator           Reflection
|                   |
TypeSchema ---> Generated Code ---> TypeSchema
</pre>
</figure>

<hr>

<p>In this case the TypeSchema on the left is identical to the TypeSchema on the right. To give you a practical example lets
take a look at the following TypeSchema specification:</p>

<h2>TypeSchema</h2>

<pre>{
  "definitions": {
    "Student": {
      "type": "struct",
      "properties": {
        "firstName": {
          "type": "string"
        },
        "lastName": {
          "type": "string"
        },
        "age": {
          "type": "integer"
        }
      }
    }
  },
  "root": "Student"
}
</pre>

<p>Through the code generator we can turn this specification into actual code, in this example
we use the Java generator.</p>

<h2>Generated Java Code</h2>

<pre>import com.fasterxml.jackson.annotation.*;

public class Student {
    private String firstName;
    private String lastName;
    private Integer age;

    @JsonSetter("firstName")
    public void setFirstName(String firstName) {
        this.firstName = firstName;
    }

    @JsonGetter("firstName")
    public String getFirstName() {
        return this.firstName;
    }

    @JsonSetter("lastName")
    public void setLastName(String lastName) {
        this.lastName = lastName;
    }

    @JsonGetter("lastName")
    public String getLastName() {
        return this.lastName;
    }

    @JsonSetter("age")
    public void setAge(Integer age) {
        this.age = age;
    }

    @JsonGetter("age")
    public Integer getAge() {
        return this.age;
    }
}
</pre>

<p>Now we can use the <a href="https://github.com/apioo/typeschema-reflection-java">reflection library</a> to transform this model back into a TypeSchema
specification which looks exactly like the schema defined above.</p>

<p>This should give you a rough understanding how TypeSchema works, for more details please take a look at the <a href="https://typeschema.org/">website</a>
or <a href="https://app.typehub.cloud/d/typehub/typeschema">specification</a>.</p>

<h2>Changes</h2>

<p>With the latest version we have moved away from the JSON Schema compatibility which we had for some years, this means we now use dedicated keywords
which are not compatible with JSON Schema so you need to decide whether you want to use TypeSchema or JSON Schema. The following list covers the
important changes.</p>

<p><b>Validation</b></p>

<p>We have removed all validation keywords from our specification i.e. <code>required</code> or <code>minLength</code> to make clear that TypeSchema
helps you only to model your data, it is not intended to validate your data. We also no longer use the dollar sign <code>$</code> at our keywords since
they make it more complicated for code generators to process.</p>

<p>We think that validation must be done in your domain layer, where you also generate fitting error messages. At TypeSchema you only describe which
fields are available and our code generator can then generate DTOs for every object structure. These DTOs can then be used at your domain layer
to validate the incoming data.</p>

<p><b>Union</b></p>

<p>We have removed support of the <code>oneOf</code> keyword. At the code generator we have noticed that for dynamically typed languages it is easy
to represent actual unions, statically typed languages like Java or C# have a much harder time to represent such dynamic data types. But they all
can represent a tagged union. This is also the concept which is now supported at TypeSchema, instead of guessing the fitting schema
a user needs to provide a concrete type identifier which is mapped to a concrete type definition. This is also
<a href="https://github.com/apioo/typeschema/blob/master/specification/typeschema.json#L130">heavily used</a> at our meta-schema to describe the TypeSchema
specification itself.</p>

<p><b>Type</b></p>

<p>Because of this union change we now also require a type property on every type. For example previously you could use the <code>$ref</code> keyword
now you need to use the "reference" type s.</p>

<pre>{
  "type": "reference",
  "target": "My_Type"
}
</pre>

<p>I'm really happy with the current TypeSchema version and I think we have made many solid designe choices for the future. Basically TypeSchema could
evolve into a general JSON format to represent a model in a language neutral format.</p>

<h2>Ecosystem</h2>

<p>To give you a short outlook into the ecosystem, there are several projects in development which are basically based on TypeSchema. At first there is
a new specification called <a href="https://typeapi.org/">TypeAPI</a> which helps to describe complete REST APIs for code generation, which internally
also uses the TypeSchema models. Then there is a platform called <a href="https://typehub.cloud/">TypeHub</a> which helps to manage TypeSchema/TypeAPI
specifications and the <a href="https://sdkgen.app/">SDKgen</a> app which provides a great code generator to turn an TypeSchema/TypeAPI specification
into client code.</p>

]]></content>
    </entry>
    <entry>
        <title>Introducing the DeutschlandAPI project</title>
        <updated>2024-09-07T23:13:00Z</updated>
        <summary>
            In this post I like to make a short introduction to the DeutschlandAPI project and share general thoughts about the concept of a country API.
        </summary>
        <category term="project" />
        <category term="api" />
        <category term="open-government" />
        <category term="open-data" />
        <content type="html"><![CDATA[

<p>I like to introduce you to the <a href="https://deutschland-api.dev/">DeutschlandAPI</a> project. The DeutschlandAPI
is basically an open API which combines and aggregates multiple open government APIs of germany into a single
consistent and easy to use API. This project is a first step to help developers get open and public information
of germany.</p>

<p>While building this API I thought about the general concept of a country API. Basically a standard API which is provided
by each country to get all available information of the country. This could enable many great use-cases where an
app can dynamically get all up-to-date information about a specific country. In the following I will go through
interesting fields which could be useful for such a country API.</p>

<h2>Geodata</h2>

<p>At first the API should expose all basic information how the land of a country is structured, in germany we can
split this up in states, districts and cities but for other countries this may be different. This could also include
streets so that apps can always validate correct address data and build up-to-date dropdowns.

<h2>Companies</h2>

<p>Every developed country has some sort of register where every official company is registered. In germany we have the
<a href="https://www.bundesanzeiger.de/">Bundesanzeiger</a> which basically is such a register, you can see also the annual accounts
for each company, but I think it would be enough to have a register which lists the company names, corporate form, business objective,
the physical address and a link to the website.</p>

<p>The Bundesanzeiger has unfortunately no public API so it is not included in the DeutschlandAPI, but I would like to add this in
the future. Such an endpoint could make it easier to get information about all companies inside a country. Today there are even services
available which sell these kind of company information, but I think it would add a great value to have such directories free available.</p>

<h2>Warnings</h2>

<p>Most countries have also a basic warning system, to warn the citizens in case of fire, extreme whether, biological or nuclear events.
In germany we have the <a href="https://www.bbk.bund.de/DE/Warnung-Vorsorge/Warnung-in-Deutschland/MoWaS/mowas_node.html">MoWaS</a> which
basically provides a warning system covering those events. This is also integrated in the DeutschlandAPI project.</p>

<h2>Statistics</h2>

<p>It would be great to have general statistics about a country like the population, GDP or unemployment rate. In germany we have the
<a href="https://www-genesis.destatis.de">Statistisches Bundesamt</a> which collects all kind of statistical information of germany,
but there are really many statistics about many topics like the population, education, habitation, economy, trade, finance etc. I am
currently trying to figure out which of these information would be really valuable for such a statistic endpoint.</p>

<h2>Jobs</h2>

<p>Most countries have a job search which is managed by the government. In germany we have the <a href="https://www.arbeitsagentur.de/">Arbeitsagentur</a>
which basically is such a job platform managed by the government. This could help to integrate job searches into different apps depending on the
country. There are of course also many private networks available like <a href="https://www.linkedin.com/">LinkedIn</a> but it would be great to integrate
a general job search provided by the government.</p>

<h2>Electricity</h2>

<p>A key information of each country is also the power production and consumption. We could add an endpoint where we simply return
the current (or maybe also historical) values how much power a country has produced or consumed. This is also a great indicator
how developed a country is.</p>

<h2>Conclusion</h2>

<p>The mentioned fields are first ideas which could be useful for a general country API. Those described endpoints are also read-only,
if we think about <code>POST</code> endpoints we could open up also many more interesting use cases like replacing emergency numbers like
110 with a post endpoint where every citizen could send a request. But those endpoints would require a safe authentication of a citizen
which is currently not possible. With the DeutschlandAPI project I have tried to build a first country API, if you also like to implement
a similar API for your country please take a look at our <a href="https://api.deutschland-api.dev/apps/redoc/">API documentation</a>.</p>

]]></content>
    </entry>
    <entry>
        <title>Building infrastructure software without central authority</title>
        <updated>2024-08-30T18:40:00Z</updated>
        <summary>
            In this post I think about building software as infrastructure tool which works without central authority
        </summary>
        <category term="idea" />
        <category term="software" />
        <category term="decentralization" />
        <content type="html"><![CDATA[

<p>To better explain the problem I am thinking about I like to go back in time.</p>

<h2>Freshmeat</h2>

<p>At the start of my open source journey there was a website called Freshmeat, which was used by developers to announce new
releases, you could also browse and find existing projects. This was before GitHub existed and at that time I really liked
this site as a central place to get information. Over time the demand decreased and the site closed, there is currently still
a replacement active called <a href="https://freshcode.club">freshcode.club</a> but it has no longer the traction of the original service.</p>

<h2>Awesome lists</h2>

<p>I think the modern successor of Freshmeat are so-called "Awesome lists" on GitHub, basically these are simply repositories
with markdown files containing links to interesting tools. The reason why these lists overtook software directories like Freshmeat
is probably socially, because now every user could add suggestions by opening a pull request. This is really great and has
helped to create "awesome" lists but over time this has still some problems:</p>

<ul>
    <li>Since every repository has a central owner which needs to accept and merge pull requests there are many lists where
    the original author is no longer active so that nobody can modify an existing list. You could of course fork such
    a list but then you have many duplicated lists and nobody knows the currently active maintained list.</li>
    <li>Most lists contain also out-dated content since it is really difficult to keep those lists up-to-date.</li>
</ul>

<h2>Infrastructure software</h2>

<p>Software directories like Freshmeat and also Awesome lists have both the problem that they have a central authority
which needs to curate each entry. I am currently thinking about a solution for this problem so that we
can build software without a central authority. This could allow us to create lists which are always up-to-date and evolve
over a long period of time. Because of this I like to call this "infrastructure software" basically a piece of software which
can run on a server without moderation or central authority.</p>

<p>You may think, this sounds cool but how could this be possible and how can you prevent spam?</p>

<p>I think we should come back to the basic building blocks of the internet. To protect against spam we need a resource which is limited,
for the internet the perfect limitation is a domain. You can only add an entry to our list if you have a custom domain, this
automatically limits participation only to users with a custom domain. To verify the ownership of the domain we could add
a verification through a DNS TXT record.</p>

<p>As second step if a domain was registered to our list we reverse the data flow, instead of adding an entry directly to a central
database the domain needs to provide an endpoint where the information gets returned. For example, we could request on
every domain the following path <code>/.well-known/software.json</code> and check the response, on success this
endpoint returns all information of our entry on the list.</p>

<p>Through this the owner of the domain can easily update the information of the entry by simply updating the <code>software.json</code>
resource on the server. Our list aggregation service can then check all domains periodically for updates. We could also delete or hide
an entry in case the resource returns an invalid status code like 404 or 500.</p>

<h2>Conclusion</h2>

<p>I think this idea is really great and could help to build software directories which could be always up-to-date and run
for a really long time. Every user on the internet can add a new entry by submitting a custom domain to the list.
There are still some challenges since we need a great JSON format to describe a software entry and there needs to be
a great aggregation service which provides an intuitive UI, but those technical challenges are easy solvable.</p>

<p>Currently this is still an early idea and there is no implementation, so please <a href="https://www.apioo.de/en/contact">contact me</a>
if you like the idea and would participate on such a directory. I am really motivated to move this forward to make the web more decentralized
and better.</p>

]]></content>
    </entry>
    <entry>
        <title>Reboot my personal blog</title>
        <updated>2024-08-24T14:57:00Z</updated>
        <summary>
            This post introduces the reboot of my personal blog, I will explain the reasons and the topics which you can
            expect in the future.
        </summary>
        <category term="meta" />
        <content type="html"><![CDATA[

<p>With this post I like to reboot my personal blog. In the past I have used for a long time
<a href="https://medium.com/@chriskapp">medium.com</a> as blogging platform but there are several reasons why I am
no longer happy with the platform. I have thought about choosing one of the thousand alternative platforms for blogging
but in the end they all have downsides. Instead of going through all downsides I like to share my thoughts about the
advantages of a self-hosted blog, maybe I can convince also some readers to start again with a self-hosted blog.</p>

<h2>Data sovereignty</h2>

<p>If you host your own blog the content of your blog is under your control. An external blogging platform is a company
which needs to make money, they need to somehow use your blogging content to create revenue since they offer the platform
mostly for free. This is done by adding some kind of partner program or paywalls. On your own blog you are complete free
from those topics and you can get sure that your content is not misused.</p>

<h2>Data durability</h2>

<p>Your thoughts and ideas which you write are an important part of your legacy. You probably want that this content
is also available after your lifetime. Blogging platforms are limited to the lifetime of the company behind the platform
which is often not too long, if the company closes your content will also disappear. If you host your own blog you
have automatically multiple mechanisms to archive your content. In my case I use a public GitHub
<a href="https://github.com/chriskapp/personal-website/blob/main/resources/blog.xml">repository</a> where all
posts are stored. Then your blog is probably also covered by <a href="https://archive.org/">archive.org</a> which
creates over time a complete backup of your blog. Through your own domain and content you basically participate in the
history of the internet.</p>

<h2>Data quality</h2>

<p>Most blogging platforms provide some kind of <abbr title="What You See Is What You Ge">WYSIWYG</abbr> editor to write
your content. Such editors often produce ugly HTML and they are also limited. Especially for development content I find
often examples where code examples or code-highlighting are broken. If you want to preserve your content for the long term
it is probably better to write the HTML content by your self, this ensures better data quality and makes it better readable.</p>

<h2>Decentralization</h2>

<p>This is an idealistic point but if you host your own blog you help to decentralize the web. You may know
the largest problem of the current web is centralization, this means that there are only some centralized platforms or
so called data silos like Twitter, Facebook etc. where all content gets created. In the end those platforms are dependent
on your content, if you decide to move this content to your own blog you remove some power from those platforms.</p>

<h2>Conclusion</h2>

<p>These points have convinced me to start again with my own self-hosted blog. But there are of course also some
disadvantages. The largest disadvantage is probably discoverability, on a central platform you get
automatically readers from the users on the platform, on your own blog you depend on a search engine to find
new readers. In the future it would be cool to have some kind of aggregation service where self-hosted blogs could
register to reach a wider audience, to support those self-hosted blogs.</p>

<h2>Future</h2>

<p>Regarding this blog, in the future I will write content around my open source projects and in general development topics like API management,
REST, code generation, specifications and decentralization. I will also go through my old <a href="https://chriskapp.medium.com/">medium.com</a>
posts and transfer them to this blog. If you are interested feel free to subscribe to the <a href="https://chrisk.app/feed">feed</a>.

]]></content>
    </entry>
</feed>
